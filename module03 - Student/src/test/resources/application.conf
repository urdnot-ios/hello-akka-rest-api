akka {
  kafka.producer {
    # Properties for akka.kafka.ProducerSettings can be
    # defined in this section or a configuration section with
    # the same layout.

    # Config path of Akka Discovery method
    # "akka.discovery" to use the Akka Discovery method configured for the ActorSystem
    discovery-method = akka.discovery

    # Set a service name for use with Akka Discovery
    # https://doc.akka.io/docs/alpakka-kafka/current/discovery.html
    service-name = ""

    # Timeout for getting a reply from the discovery-method lookup
    resolve-timeout = 3 seconds

    # Tuning parameter of how many sends that can run in parallel.
    # In 2.0.0: changed the default from 100 to 10000
    parallelism = 10000

    # Duration to wait for `KafkaProducer.close` to finish.
    close-timeout = 60s

    # Call `KafkaProducer.close` when the stream is shutdown. This is important to override to false
    # when the producer instance is shared across multiple producer stages.
    close-on-producer-stop = true

    # Fully qualified config path which holds the dispatcher configuration
    # to be used by the producer stages. Some blocking may occur.
    # When this value is empty, the dispatcher configured for the stream
    # will be used.
    use-dispatcher = "akka.kafka.default-dispatcher"

    # The time interval to commit a transaction when using the `Transactional.sink` or `Transactional.flow`
    # for exactly-once-semantics processing.
    eos-commit-interval = 100ms

    # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
    # can be defined in this configuration section.
    #    kafka-clients {
    #      bootstrap.servers = "localhost"
    #    }
  }
  kafka.consumer {
    # Config path of Akka Discovery method
    # "akka.discovery" to use the Akka Discovery method configured for the ActorSystem
    discovery-method = akka.discovery

    # Set a service name for use with Akka Discovery
    # https://doc.akka.io/docs/alpakka-kafka/current/discovery.html
    service-name = ""

    # Timeout for getting a reply from the discovery-method lookup
    resolve-timeout = 3 seconds

    # Tuning property of scheduled polls.
    # Controls the interval from one scheduled poll to the next.
    poll-interval = 50ms

    # Tuning property of the `KafkaConsumer.poll` parameter.
    # Note that non-zero value means that the thread that
    # is executing the stage will be blocked. See also the `wakup-timeout` setting below.
    poll-timeout = 50ms

    # The stage will delay stopping the internal actor to allow processing of
    # messages already in the stream (required for successful committing).
    # This can be set to 0 for streams using `DrainingControl`.
    stop-timeout = 30s

    # Duration to wait for `KafkaConsumer.close` to finish.
    close-timeout = 20s

    # If offset commit requests are not completed within this timeout
    # the returned Future is completed `CommitTimeoutException`.
    # The `Transactional.source` waits this ammount of time for the producer to mark messages as not
    # being in flight anymore as well as waiting for messages to drain, when rebalance is triggered.
    commit-timeout = 15s

    # If commits take longer than this time a warning is logged
    commit-time-warning = 1s

    # Not relevant for Kafka after version 2.1.0.
    # If set to a finite duration, the consumer will re-send the last committed offsets periodically
    # for all assigned partitions. See https://issues.apache.org/jira/browse/KAFKA-4682.
    commit-refresh-interval = infinite

    # Fully qualified config path which holds the dispatcher configuration
    # to be used by the KafkaConsumerActor. Some blocking may occur.
    use-dispatcher = "akka.kafka.default-dispatcher"

    # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
    # can be defined in this configuration section.
    kafka-clients {
      # Disable auto-commit by default
      enable.auto.commit = false
      auto.offset.reset = earliest
      group.id = "devgroup"
    }

    # Time to wait for pending requests when a partition is closed
    wait-close-partition = 500ms

    # Limits the query to Kafka for a topic's position
    position-timeout = 5s

    # When using `AssignmentOffsetsForTimes` subscriptions: timeout for the
    # call to Kafka's API
    offset-for-times-timeout = 5s

    # Timeout for akka.kafka.Metadata requests
    # This value is used instead of Kafka's default from `default.api.timeout.ms`
    # which is 1 minute.
    metadata-request-timeout = 5s

    # Interval for checking that transaction was completed before closing the consumer.
    # Used in the transactional flow for exactly-once-semantics processing.
    eos-draining-check-interval = 30ms

    # Issue warnings when a call to a partition assignment handler method takes
    # longer than this.
    partition-handler-warning = 5s

    # Settings for checking the connection to the Kafka broker. Connection checking uses `listTopics` requests with the timeout
    # configured by `consumer.metadata-request-timeout`
    connection-checker {

      #Flag to turn on connection checker
      enable = false

      # Amount of attempts to be performed after a first connection failure occurs
      # Required, non-negative integer
      max-retries = 3

      # Interval for the connection check. Used as the base for exponential retry.
      check-interval = 15s

      # Check interval multiplier for backoff interval
      # Required, positive number
      backoff-factor = 2.0
    }

    # Protect against server-side bugs that cause Kafka to temporarily "lose" the latest offset for a consumer, which
    # then causes the Kafka consumer to follow its normal 'auto.offset.reset' behavior. For 'earliest', these settings
    # allow the client to detect and attempt to recover from this issue. For 'none' and 'latest', these settings will
    # only add overhead. See
    # https://doc.akka.io/docs/alpakka-kafka/current/errorhandling.html#unexpected-consumer-offset-reset
    # for more information
    offset-reset-protection {
      # turns on reset protection
      enable = false
      # if consumer gets a record with an offset that is more than this number of offsets back from the previously
      # requested offset, it is considered a reset
      offset-threshold = 9223372036854775807
      # if the record is more than this duration earlier the last received record, it is considered a reset
      time-threshold = 100000 days
    }
  }
  testkit.testcontainers {

    # define these settings to select a different Kafka/ZooKeeper docker image
    # we recommend using Confluent Platform docker images and using the same version across all images
    # Confluent publishes images on DockerHub: https://hub.docker.com/r/confluentinc/cp-kafka/tags
    # Kafka versions in Confluent Platform: https://docs.confluent.io/current/installation/versions-interoperability.html
    zookeeper-image = "confluentinc/cp-zookeeper"
    zookeeper-image-tag = ${akka.kafka.testkit.testcontainers.confluent-platform-version}
    kafka-image = "confluentinc/cp-kafka"
    kafka-image-tag = ${akka.kafka.testkit.testcontainers.confluent-platform-version}
    schema-registry-image = "confluentinc/cp-schema-registry"
    schema-registry-image-tag = ${akka.kafka.testkit.testcontainers.confluent-platform-version}
    confluent-platform-version = "6.1.1"

    # the number of Kafka brokers to include in a test cluster
    num-brokers = 1

    # set this to use a replication factor for internal Kafka topics such as Consumer Offsets and Transaction log.
    # this replication factor must be less than or equal to `num-brokers`
    internal-topics-replication-factor = 1

    # set this to true to use launch a testcontainer for Confluent Schema Registry
    use-schema-registry = false

    # set this to true to stream the STDOUT and STDERR of containers to SLF4J loggers
    # this requires the SLF4J dependency to be on the classpath and the loggers enabled in your logging configuration
    container-logging = false

    # set this to the total length of time to wait for a Kafka container cluster to start. this includes all brokers
    # zookeeper, and schema registry nodes. note that this can take a considerable time in limited resource environments.
    cluster-start-timeout = 360 s

    # set this to the total length of time to wait for a Kafka container readiness check to complete. note that this can
    # take a considerable time in limited resource environments.
    readiness-check-timeout = 360 s
  }
}